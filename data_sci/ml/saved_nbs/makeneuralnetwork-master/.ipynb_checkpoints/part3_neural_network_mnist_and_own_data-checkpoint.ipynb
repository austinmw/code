{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# python notebook for Make Your Own Neural Network\n",
    "# code for a 3-layer neural network, and code for learning the MNIST dataset\n",
    "# this version trains using the MNIST dataset, then tests on our own images\n",
    "# (c) Tariq Rashid, 2016\n",
    "# license is GPLv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "# scipy.special for the sigmoid function expit()\n",
    "import scipy.special\n",
    "# library for plotting arrays\n",
    "import matplotlib.pyplot\n",
    "# ensure the plots are inside this notebook, not an external window\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper to load data from PNG image files\n",
    "import scipy.misc\n",
    "# glob helps select multiple files using patterns\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "    \n",
    "    \n",
    "    # initialise the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # set number of nodes in each input, hidden, output layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # link weight matrices, wih and who\n",
    "        # weights inside the arrays are w_i_j, where link is from node i to node j in the next layer\n",
    "        # w11 w21\n",
    "        # w12 w22 etc \n",
    "        self.wih = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors) \n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n",
    "        \n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the mnist training data CSV file into a list\n",
    "training_data_file = open(\"mnist_dataset/mnist_train_100.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train the neural network\n",
    "\n",
    "# epochs is the number of times the training data set is used for training\n",
    "epochs = 10\n",
    "\n",
    "for e in range(epochs):\n",
    "    # go through all records in the training data set\n",
    "    for record in training_data_list:\n",
    "        # split the record by the ',' commas\n",
    "        all_values = record.split(',')\n",
    "        # scale and shift the inputs\n",
    "        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = numpy.zeros(output_nodes) + 0.01\n",
    "        # all_values[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ...  my_own_images/2828_my_own_2.png\n",
      "0.01\n",
      "1.0\n",
      "loading ...  my_own_images/2828_my_own_3.png\n",
      "0.01\n",
      "1.0\n",
      "loading ...  my_own_images/2828_my_own_4.png\n",
      "0.01\n",
      "0.930118\n",
      "loading ...  my_own_images/2828_my_own_5.png\n",
      "0.01\n",
      "0.868\n",
      "loading ...  my_own_images/2828_my_own_6.png\n",
      "0.01\n",
      "1.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'e'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-54d918467417>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# use the filename to set the correct label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_file_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# load image data from png files into an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'e'"
     ]
    }
   ],
   "source": [
    "# our own image test data set\n",
    "our_own_dataset = []\n",
    "\n",
    "# load the png image data as test data set\n",
    "for image_file_name in glob.glob('my_own_images/2828_my_own_*.png'):\n",
    "    \n",
    "    # use the filename to set the correct label\n",
    "    label = int(image_file_name[-5:-4])\n",
    "    \n",
    "    # load image data from png files into an array\n",
    "    print (\"loading ... \", image_file_name)\n",
    "    img_array = scipy.misc.imread(image_file_name, flatten=True)\n",
    "    \n",
    "    # reshape from 28x28 to list of 784 values, invert values\n",
    "    img_data  = 255.0 - img_array.reshape(784)\n",
    "    \n",
    "    # then scale data to range from 0.01 to 1.0\n",
    "    img_data = (img_data / 255.0 * 0.99) + 0.01\n",
    "    print(numpy.min(img_data))\n",
    "    print(numpy.max(img_data))\n",
    "    \n",
    "    # append label and image data  to test data set\n",
    "    record = numpy.append(label,img_data)\n",
    "    our_own_dataset.append(record)\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.59539638]\n",
      " [ 0.60514818]\n",
      " [ 0.95510719]\n",
      " [ 0.17192581]\n",
      " [ 0.80528401]\n",
      " [ 0.681782  ]\n",
      " [ 0.19134315]\n",
      " [ 0.86722601]\n",
      " [ 0.01293315]\n",
      " [ 0.36644082]]\n",
      "network says  2\n",
      "no match!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e3ab5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the neural network withour own images\n",
    "\n",
    "# record to test\n",
    "item = 4\n",
    "\n",
    "# plot image\n",
    "matplotlib.pyplot.imshow(our_own_dataset[item][1:].reshape(28,28), cmap='Greys', interpolation='None')\n",
    "\n",
    "# correct answer is first value\n",
    "correct_label = our_own_dataset[item][0]\n",
    "# data is remaining values\n",
    "inputs = our_own_dataset[item][1:]\n",
    "\n",
    "# query the network\n",
    "outputs = n.query(inputs)\n",
    "print (outputs)\n",
    "\n",
    "# the index of the highest value corresponds to the label\n",
    "label = numpy.argmax(outputs)\n",
    "print(\"network says \", label)\n",
    "# append correct or incorrect to list\n",
    "if (label == correct_label):\n",
    "    print (\"match!\")\n",
    "else:\n",
    "    print (\"no match!\")\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
